\documentclass{article}
\usepackage[UTF8]{ctex}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{bm}
% \usepackage{calrsfs}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}

\newtheorem{problem}{问题}
\newtheorem{thm}{定理}

\title{两类内点法介绍}
\author{张瑜安\\ 计算机科学与技术学院 \\21921060}
\date{}
\begin{document}
\maketitle
\section{介绍}
内点法是求解线性规划问题非常优秀的一类方法，其做法是通过在约束可行域中的一点出发，
迭代探索附近的点来逼近最优解，这也是“内点”这个名字的含义。在线性规划问题的求解上，
内点法比单纯形法要快，而且内点法一般保证了多项式复杂度，单纯形法则没有。
内点法也被拓展到更加一般的凸优化问题当中。

到目前为止，内点法是相当流行的凸优化问题求解方法，主流的求解器都会集成这类方法。实际
使用的时候，它的速度很快，迭代次数也很少。但它也有一定的局限性，本文介绍的方法对函数进行了
二阶导连续的限制，相比于使用次梯度的方法适用范围更窄一些；
另一方面它是局部方法，并不用于求解全局解。

内点法的一般思路是使用可微的障碍函数（Barrier Function）代替一个理想的惩罚函数，
同时将优化问题变成求解最优条件的问题，就可以使用牛顿法来解。本文介绍两种思路相承接的方法，
第一类是直接应用障碍函数、从中心路径逼近的方法，第二类是考虑对偶变量一起优化的原始
对偶方法。在\ref{center_to_dual}一节中将会展示如何从第一种方法
启发得到第二种。


\section{背景调研}
内点法起源可以追溯到1955年，Frisch~\cite{frisch1955logarithmic}当时就在用障碍函数做凸优化。
到上世纪六十年代，这类法主要被应用于非线
性的优化，因为当时单纯形法在线性规划中拥有不可撼动的地位。到七十年代相关研究
越来越少，原因之一是障碍函数边缘牛顿方程呈现出病态性质。

1984年Karmarkar在线性规划领域提出了
一个多项式时间复杂度的算法~\cite{karmarkar1984new}，实际效率比单纯形法快得多。
1986年Gill等人的研究~\cite{gill1986projected}表明Karmarkar的映射方法和
障碍函数的方法本质上十分接近，从而障碍函数方法重新成为研究热点。这类方法之后也被拓展到更加一般的凸优化问题当中，
如非线性自和谐函数~\cite{nesterov1994interior}。

与此同时，障碍函数在线性规划问题的应用也启发出了另一类相似但是本质不同的方法，就是原始对偶法~\cite{wright1997primal}。
障碍函数法严格地跟踪中心路径，原始对偶方法则放宽了跟踪中心路径的限制，但是其精度和效率比障碍函数更好。
到今天为止原始对偶内点法仍然具有相当的竞争力，在线性规划和二次规划问题中都会考虑这类方法。


\section{报告组织}
本文第一节对内点法做了简单介绍，第二节介绍了内点法的历史发展。
第三节就是本节，介绍文章结构，第四节约定记号并简述本文关注的凸优化问题、对偶问题、KKT条件和牛顿法这些必要知识。

第五节首先介绍了重要工具障碍函数，然后介绍了直接使用跟踪中心路径的障碍函数方法和原始对偶方法，并且说明了原始对偶方法可以如何从障碍函数启发得到。第六节对第五节中的方法进行了算法复杂度分析，并简要分析其优劣。
这两节内容主要来自于~\cite{10.5555/993483}和~\cite{nesterov2018lectures}两本书。

第七节介绍了内点法的应用，最后，第八节对内点法做了总结。
\section{记号和预备知识}
\subsection{记号}
\begin{center}
    \begin{tabular}{ c c c }
     符号 & 含义 \\ 
     \hline
     $\mathbb{R}$ & 实数集\\  
     $\bm x,\bm 1,\bm 0$ & 用加粗表示向量，区别于一个数\\
     $\textbf{dom}f$ & $f(\bm x)$的定义域  \\
     $\succ,\prec,\succeq,\preceq$ & 用于矩阵和向量的广义不等号\\
     $\nabla$ & 微分算子\\
     $\textbf{f}(\bm x)$& 向量函数，用粗体区别于单值函数 \\
     $\text{D}\textbf{f}(\bm x)$&$\textbf{f}(\bm x)$的雅可比矩阵\\
     $\textbf{diag}(\bm x)$ & 将向量$\bm x$变成对角矩阵\\
     $\mathcal{S}_{\mu,L}^{2,2}(\mathbb{R}^n)$ & 二阶可微，二阶Lipschitz连续的强凸函数类，二阶导常量为$L$，凸参数为$\mu$\\
     $\|\cdot\|_p$ & 矩阵或者向量的$p$-范数，未标明$p$的默认为$2$-范数。\\
     $\log$ & 没有写底数时默认底数是自然对数$\text{e}$\\
     $\mathcal O$ & 数量级上界\\
    \end{tabular}
\end{center}
\subsection{预备知识}
\label{pre_know}
本文考虑的凸优化问题具有如下形式：
\begin{problem}
最小化$f_0(\bm x)$，使得$f_i(\bm x)\le 0(i=1,2,...,m),A\bm x=\bm{b}$成立，其中$f_i(\bm x):\mathbb{R}^n\rightarrow\mathbb{R}(i=0,1,...,m)$均为凸函数，$A\in\mathbb{R}^{p\times n},\bm b\in\mathbb{R}^p$。
\label{general_convex_prob}
\end{problem}

上述问题中$\bm x$的维数是$n$，约束一共是$m+p$个，其中有$p$个是等式线性约束。
记定义域$\mathcal{D}=\bigcap\limits_{i=0}^{m}\textbf{dom}f_i$，
定义该问题的拉格朗日函数和对偶函数为：
\begin{equation}
    L(\bm x,\bm\lambda, \bm\nu)=f_0(\bm x)+\sum\limits_{i=1}^m\lambda_if_i(\bm x)+\bm\nu^T(A\bm x-\bm b)\label{lagrange_function}
\end{equation}
\begin{equation}
    g(\bm\lambda, \bm\nu)=\inf_{\bm x\in D}\{L(\bm x,\bm\lambda, \bm\nu)\}\label{dual_function}
\end{equation}
其中$\bm\lambda=(\lambda_1,\lambda_2,...,\lambda_m)\in\mathbb R^m,\bm\nu\in\mathbb{R}^p$，那么问题\ref{general_convex_prob}的对偶问题为：
\begin{problem}
最大化$g(\bm\lambda,\bm\nu)$，使得$\bm\lambda\succeq\bm 0$。\label{dual_problem}
\end{problem}

记问题\ref{general_convex_prob}的最优值为$p^*$，问题\ref{dual_problem}的最优值为$d^*$，
那么$d^*\le p^*$。使$d^*=p^*$成立的一个条件是\textbf{Slater条件}：存在一点$\bar{\bm x}\in \textbf{relint}\mathcal D$使得
$$f_i(\bar{\bm x})<0(i=1,...,m),A\bar{\bm x}=\bm b$$
成立。现在假设$f_i(\bm x)(i=0,1,...,m)$\textbf{可微}，那么可以推导出\textbf{Karush-Kuhn-Tucker条件}，即当存在$\bm x^*,\bm\lambda^*,\bm\nu^*$满足
\begin{equation}
    \label{kkt}
    \begin{gathered}
    A\bm x^*=\bm b,f_i(\bm x^*)\le 0,i=1,...,m \\
    \bm\lambda^*\succeq \bm 0 \\
    \lambda^*_if_i(\bm x^*)=0,i=1,...,m\\
    \nabla f_0(\bm x^*)+\sum\limits_{i=1}^m{\lambda^*_i}\nabla f_i(\bm x^*)+A^T\bm\nu^*=\bm 0\\
    \end{gathered}
\end{equation}
时，$d^*=p^*$，并且$\bm x^*,(\bm\lambda^*,\bm\mu^*)$分别是原问题和对偶问题的最优解。

不考虑不等式约束，仅考虑等式约束，那么上述KKT条件简化为：
\begin{equation}
    A\bm x^*=\bm b,\nabla f_0(\bm x^*)+A^T\bm\nu ^*=\bm 0\label{equation_constraint_kkt}
\end{equation}

加强$f_0(\bm x)$，假设$f_0(\bm x)\in \mathcal S_{\mu,L}^{2,2}(\mathbb{R}^n)$，那么就可以用\textbf{牛顿法}求解约束\eqref{equation_constraint_kkt}中的
$\bm x^*$。用$\bm x+\Delta \bm x$代替式\eqref{equation_constraint_kkt}
中的$\bm x^*$，并对$\nabla f_0(\bm x+\Delta \bm x)$做一阶近似就可以得到
计算迭代方向$\Delta \bm x$的方程：
\begin{equation}
\begin{pmatrix}
    \nabla^2f_0(\bm x) & A^T\\
    A & \bm 0
\end{pmatrix}
\begin{pmatrix}
    \Delta \bm x\\
    \bm\nu^*
\end{pmatrix}=
\begin{pmatrix}
    -\Delta f_0(\bm x)\\
    \bm 0
\end{pmatrix}\label{newton_for_equation}\end{equation}
如果我们能找到一个初始可行点$\bm x_0$，就可以用$\bm x_k=\bm x_{k-1}+h\Delta \bm x$来求解$\bm x^*$。
牛顿法将会经历两个阶段：
\begin{enumerate}
    \item \textbf{阻尼阶段}。在达到快速收敛域之前，$h$的选择使用\textbf{回溯直线搜索}策略，上课提到这个策略是在Proximal Gradient Method，
    其直线搜索的目标是Lipschitz常量，不过我们这里
    直线搜索的目标是\textbf{Goldstein-Armijio规则}：引入$0<\alpha< 0.5$参数来控制$h$满足$f(\bm x+h\Delta\bm x)\le f(\bm x)+\alpha h\nabla f(\bm x)^T\Delta\bm x$。我们在搜索中
    每次将$h$乘以$0<\sigma<1$直到$h$满足该规则。
    （Goldstein-Armijio规则还有引入$\beta$进行下界控制，不过不影响后续复杂度分析，所以未使用此规则）
    \item \textbf{二次收敛阶段}。足够接近最优解时，收敛速度很快，一般取$h=1$。
\end{enumerate}
上面两个阶段的收敛速度分析会在\ref{time_complexity_newton}介绍。
到此为止，我们有了一个求解仅含等式约束的凸优化问题的牛顿方法。
\ref{text_barrier_method}将会介绍如何利用障碍函数将不等式约束融合进目标函数，从而可以使用此处所描述
的牛顿法求解。
\label{text4_2}
\section{方法}
\subsection{障碍函数和中心路径}
我们试图将问题\ref{general_convex_prob}转换为等式约束问题，因为在\ref{text4_2}
中已经提出了一个解决等式约束问题的牛顿方法。引入如下函数：
$$I_-(u)=\begin{cases}
    0 & u\le 0 \\
    \infty & u > 0
\end{cases}$$
用该函数来惩罚大于零的$f_i(\bm x),1\le i\le m$，那么问题\ref{general_convex_prob}等价于：
\begin{problem}
最小化$f_0(\bm x)+\sum\limits_{i=1}^m{I_-(f_i(\bm x))}$使得$A\bm x=\bm b$
\label{barrier_problem}
\end{problem}

问题\ref{barrier_problem}中，需要优化的目标函数在不等式约束内等于$f_0(\bm x)$，
其他区域内没有定义，所以和问题\ref{general_convex_prob}的等价是显然的。

引入$I_-(u)$后，不等式约束被融合进目标函数，只剩下等式约束。
然而问题\ref{barrier_problem}中目标函数是一个不可微的函数，我们需要做一点近似才能应用\ref{text4_2}中
的牛顿方法。用
$$\widehat I_-(u)=-(1/t)\log(-u)$$
近似$I_-(u)$（其中$t>0$为常数），问题\ref{barrier_problem}可以近似成如下问题：
\begin{problem}
    最小化$f_0(\bm x)+\sum\limits_{i=1}^m{-(1/t)\log(f_i(\bm x))}$使得$A\bm x=\bm b$
    \label{barrier_approx_prob}
\end{problem}

可以看出，$t$越大，$\widehat I_-(u)$越接近$I_-(u)$，问题\ref{barrier_approx_prob}
和问题\ref{barrier_problem}的目标函数就越接近，其解也越接近。
目标函数中的对数惩罚部分$\phi(\bm x)=-\sum\limits_{i=1}^m\log (-f_i(\bm x))$被称做问题\ref{general_convex_prob}的\textbf{对数障碍函数}。

当$f_i(\bm x)\in C_M^{2,2},i=0,...,m$时，问题\ref{barrier_approx_prob}就可以应用\ref{text4_2}中
的牛顿方法。一个朴素的思路是直接设一个很大$t$，计算在$t$下问题\ref{barrier_approx_prob}的解。
但是$t$很大时，目标函数的Hessian矩阵在可行域边界剧烈变动。所以在\ref{text_barrier_method}中
的方法将考虑逐渐增加$t$，解决一系列的问题\ref{barrier_approx_prob}来规避这个问题。

简化符号，重写问题\ref{barrier_approx_prob}：
\begin{problem}
    最小化$f_0(\bm x)+(1/t)\phi(\bm x)$，使得$A\bm x=\bm b$
    \label{barrier_approx_prob_simple}
\end{problem}

对某一$t>0$，用\textbf{中心点}$\bm x^*(t)$表示问题\ref{barrier_approx_prob_simple}的解，
将不同$t$对应的中心点集合称为问题\ref{general_convex_prob}的\textbf{中心路径}。
中心路径上的点需在障碍函数的定义域中，并且满足
式\eqref{equation_constraint_kkt}的KKT条件，即：
$$A\bm x^*(t)=\bm b,f_i(\bm x^*(t))<0,i=1,...,m$$
并且存在$\widehat{\bm \nu}\in \mathbb{R}^p$使得
\begin{equation}\nabla f_0(\bm x^*(t))+(1/t)\nabla\phi(\bm x^*(t))+A^T\widehat{\bm \nu}=\bm 0\label{center_path_kkt}\end{equation}
把式\eqref{center_path_kkt}中$\phi$的梯度展开写就是：
\begin{equation}
    \nabla f_0(\bm x^*(t))+\sum\limits_{i=1}^m{\frac{1}{-tf_i(\bm x^*(t))}\nabla f_i(\bm x^*(t))}+A^T\widehat{\bm \nu}=\bm 0\label{center_path_kkt_2}
\end{equation}

在\ref{center_to_dual}将会证明$f_0(\bm x^*(t))-p^*\le m/t$，即中心点的函数值
和最优值相差不超过$m/t$，从而我们可以在求解过程中对精度进行控制。
从该结论也可以得出当$t\rightarrow\infty$时，$\bm x^*(t)$从中心路径逼近原问题的解。下一节介绍从中心路径逼近最优解的方法。
\label{text_barrier_center_path}
\subsection{障碍函数法}
\label{text_barrier_method}
有了\ref{text_barrier_center_path}的铺垫，很自然的可以得到如下算法：

\renewcommand{\algorithmcfname}{算法}
\begin{algorithm}[H]
    % \SetKwInOut{KIN}{输入}
    % \SetKwInOut{KOUT}{输出}
    \KwIn {严格可行点$\bm x_0$,参数$t>0,\mu>1$，误差阈值$\epsilon>0$}
    \For {$i \gets 0\dots \infty $} {
        从$\bm x_i$出发，在$A\bm x=\bm b$约束下极小化$f_0(\bm x)+(1/t)\phi(\bm x)$，解出中心点$\bm x_i^*(t)$\;
        $\bm x_{i+1}\leftarrow\bm x_i^*(t)$\;
        \If{$m/t<\epsilon$} {
            \Return $\bm x_{i+1}$
        }
        $t\leftarrow \mu t$
    }
    \caption{障碍函数法}
    \label{barrier_method}
\end{algorithm}

此处对算法\ref{barrier_method}中的重要步骤进行两点说明：
\begin{enumerate}
    \item 解中心点$\bm x_i^*(t)$是仅有线性等式约束的凸优化问题，解这类问题的方法
    已经在\ref{text4_2}描述过了，使用的是牛顿法。因而该算法存在内外两层迭代。
    \item 初始的严格可行点$\bm x_0$可以通过求解问题\ref{prepare}找到，此问题和我们要求解
    的问题是同一类问题，不同之处在于该问题的初始可行解很容易找，
    因为任取定义域中满足$A\bm x=\bm b$的一点$\bm x_0$，总能找到足够大的$s_0$与$\bm x_0$一起
    作为初始解。求解严格可行点$x_0$还有其他方法，比如使用不可行初始点牛顿法，
    需要修改式\eqref{newton_for_equation}，此处不再赘述。
    \begin{problem}
        最小化$s$，使得$f_i(\bm x)\le s,i=1,...,m,A\bm x=\bm b$
        \label{prepare}
    \end{problem}
\end{enumerate} 
此处不详细介绍参数$\mu$如何影响效率以及如何调整，只简要说明。如果$\mu$较小，内层的牛顿迭代次数会很少，但是外层的$t$达到$m/\epsilon$要经过很多次的迭代。
反之，如果$\mu$较大，内层迭代次数偏多，外层迭代次数减少。实践中按需确定，一般取10～20。

思考如何让障碍方法更快。事实上，上一轮牛顿迭代的结果会被拿来做下一轮的初始点，再
精确也没用，所以其实前几轮的精度要求不需要很高，只要在接近边缘的时候才需要较高的精度，
所以前几轮牛顿迭代甚至可以压缩到只迭代一次。
事实上，接下来\ref{text_prim_dual}介绍的原始对偶方法，本质上还是粗略地
从中心路径接近最优解，不过用一次迭代代替一轮牛顿迭代。然而原始对偶法
并非障碍方法简单粗暴的改版，每次迭代还考虑了和对偶问题一起优化，因而精度和效率并存。

\subsection{原始对偶方法}
\label{text_prim_dual}
\subsubsection{从中心路径到对偶问题}
\label{center_to_dual}
中心路径和对偶问题有着十分紧密的联系。对固定的$t$，中心点是$\bm x^*(t)$，
取$\lambda_i^*(t)=-\frac{1}{tf_i(\bm x^*(t))},i=1,...,m$,令$\bm \nu^*(t)$为式\eqref{center_path_kkt}中的$\widehat{\bm\nu}$。
根据式\eqref{center_path_kkt_2}有：
$$\nabla f_0(\bm x^*(t))+\sum\limits_{i=1}^m{\bm\lambda_i^*(t)\nabla f_i(\bm x^*(t))}+A^T\bm \nu^*(t)=\bm 0$$
考虑问题\ref{general_convex_prob}的拉格朗日函数式\eqref{lagrange_function}，其关于$\bm x$的导数为：
$$\frac{\partial L(\bm x,\bm \lambda,\bm \nu)}{\partial\bm x}=
\nabla f_0(\bm x)+\sum\limits_{i=1}^m{\lambda_i\nabla f_i(\bm x)}+A^T\bm\nu$$
代入$\bm x^*(t),\bm\lambda_i^*(t),\bm\nu^*(t)$恰好为零，说明拉格朗日函数在
$\bm x^*(t)$取极大值，这样就可以求得
\begin{equation}
    \label{dual_margin}
    \begin{aligned}
    g(\bm\lambda^*(t),\bm\nu^*(t))&=f_0(\bm x^*(t))+\sum_{i=1}^m{\bm\lambda_i^*(t)f_i(\bm x^*(t))}+\bm\nu^*(t)^T(A\bm x^*(t)-\bm b)\\
    &=f_0(\bm x^*(t))-m/t
    \end{aligned}
\end{equation}

由$g(\bm\lambda^*(t),\bm\nu^*(t))\le d*=p*\le f_0(\bm x^*(t))$，
可知当$t\rightarrow\infty$，$\bm x^*(t)$从中心路径收敛于最优解的同时，$\bm\lambda^*(t),\bm\nu^*(t)$也收敛于
对偶问题的最优解，$f_0(\bm x^*(t))$与$g(\bm\lambda^*(t),\bm\nu^*(t))$分别作为上下界逼近最优解。由此得到启发，可以同时迭代$\bm x,\bm\lambda,\bm\nu$来接近
最优解。

对KKT条件式\eqref{kkt}进行修改得到式\eqref{kkt_modified}。式\eqref{kkt_modified}与\eqref{kkt}的唯一区别
就是第三组等式$\lambda_if_i(\bm x)=0$改成了$\lambda_if_i(\bm x)=1/t$。
这是从中心点和其对偶点的关系启发得到的。
\begin{equation}
    \label{kkt_modified}
    \begin{gathered}
    A\bm x=\bm b,f_i(\bm x)\le 0,i=1,...,m \\
    \bm\lambda\succeq \bm 0 \\
    \lambda_if_i(\bm x)=1/t,i=1,...,m\\
    \nabla f_0(\bm x)+\sum\limits_{i=1}^m{\lambda_i}\nabla f_i(\bm x)+A^T\bm\nu=\bm 0\\
    \end{gathered}
\end{equation}

\subsubsection{原始对偶搜索方向}
现在希望对式\eqref{kkt_modified}中的$\bm\lambda,\bm\nu,\bm x$用牛顿法迭代求解。为方便表述，
将式\eqref{kkt_modified}中的等式方程写成$\bm r_t(\bm x,\bm\lambda,\bm\nu)=\bm 0$。$\bm r_t(\bm x,\bm\lambda,\bm\nu)$由
式\eqref{kkt_vector_form}给出：
\begin{equation}
\label{kkt_vector_form}
\bm r_t(\bm x,\bm\lambda,\bm\nu)=\begin{pmatrix}
    \nabla f_0(\bm x)+\text{D}\textbf{f}(\bm x)^T\bm\lambda+A^T\bm\nu \\
    -\textbf{diag}(\bm\lambda)\textbf{f}(\bm x)-(1/t)\bm 1 \\
    A\bm x-\bm b
\end{pmatrix}
\end{equation}
其中$\textbf{f}(\bm x)=\begin{pmatrix}
    f_1(\bm x) \\
    \vdots \\
    f_m(\bm x)
\end{pmatrix}$，$\text{D}\textbf{f}(\bm x)=\begin{pmatrix}
    \nabla f_1(\bm x)^T \\
    \vdots \\
    \nabla f_m(\bm x)^T
\end{pmatrix}$是$\textbf{f}(\bm x)$的雅可比矩阵。

将式\eqref{kkt_vector_form}中$\bm r_t$的第一部分$\bm r_{dual}=\nabla f_0(\bm x)+\text{D}\textbf{f}(\bm x)^T\bm\lambda+A^T\bm\nu$称为对偶残差，第三部分$\bm r_{prim}=A\bm x-\bm b$称为原始残差，叫这个名字是因为这两者
分别可以用来衡量$\bm\lambda,\bm\nu$、$\bm x$和对偶最优解、原问题最优解的接近程度。
而第二部分$\bm r_{cent}=-\textbf{diag}(\bm\lambda)\textbf{f}(\bm x)-(1/t)\bm 1$可以用来衡量$\bm x$和中心点$\bm x^*(t)$的接近程度，因而
称其为中心残差。$\bm r_{dual}$和$\bm r_{prim}$接近于零意味着接近对偶问题和原始问题的解，中心残差则用于控制迭代的时候在中心路径附近。

要求$(\bm x,\bm\lambda,\bm\nu)$处的迭代方向$(\Delta\bm x,\Delta\bm\lambda,\Delta\bm\nu)$。令$$\bm r_t(\bm x+\Delta\bm x,\bm\lambda+\Delta\bm\lambda,\bm\nu+\Delta\bm\nu)=\bm 0$$
类似于牛顿法的分析，利用$f(\bm x+\Delta\bm x)\approx f(\bm x)+\nabla f(\bm x)\Delta\bm x,\nabla f(\bm x+\Delta \bm x)\approx\nabla f(\bm x)+\nabla^2f(\bm x)\Delta \bm x$的近似，并舍弃带有$\Delta\bm\lambda\Delta\bm x$的项，得到式\eqref{prim_dual_direction}。
\begin{equation}
    \label{prim_dual_direction}\begin{pmatrix}
    \nabla^2f_0(\bm x)+\sum\limits_{i=1}^m{\lambda_i\nabla^2f_i(\bm x)} & \text{D}\textbf{f}(\bm x)^T & A^T \\
    -\textbf{diag}(\bm\lambda)\text{D}\textbf{f}(\bm x) & -\textbf{diag}(\textbf{f}(\bm x)) & 0 \\
    A & 0 & 0
\end{pmatrix}\begin{pmatrix}
    \Delta\bm x\\
    \Delta\bm\lambda\\
    \Delta\bm\nu
\end{pmatrix}=-\bm r_t(\bm x,\bm \lambda,\bm\nu)\end{equation}

不同于障碍方法一轮牛顿迭代能找到可行解$x^*(t)$，上述计算过程中$\bm x$可能是不可行的，
$\bm\lambda,\bm\nu$同样也可能是对偶不可行的，因此不好算对偶间隙来计算误差上限。
但是收敛到一定程度后，对偶间隙可以用$\eta =-\bm f(\bm x)^T\bm\lambda$估计，这需要$\bm r_{dual},\bm r_{prim}$几乎等于零，
即$\bm\lambda,\bm\nu$、$\bm x$都可行。因此算法描述中会对$\bm r_t$三部分$\bm r_{dual},\bm r_{prim},\bm r_{cent}$的模长分别做判断，
而不是简单的控制$\|\bm r_t\|_2<\epsilon$。

\subsubsection{算法描述}
式\eqref{prim_dual_direction}给出了搜索方向，同时我们也讨论了误差上限的估计，至此可以给出
原始对偶方法：

\renewcommand{\algorithmcfname}{算法}
\begin{algorithm}[H]
    % \SetKwInOut{KIN}{输入}
    % \SetKwInOut{KOUT}{输出}
    \KwIn {$\bm x_0$满足$\bm f(\bm x_0)\prec \bm 0,\bm\lambda_0 \succ \bm 0,\bm\nu_0$，参数$t>0,\mu>1$，可行误差阈值$\epsilon_{feas}>0$和误差阈值$\epsilon>0$}
    \For {$i \gets 0\dots \infty $} {
        计算$(\Delta\bm x,\Delta\bm\lambda,\Delta\bm\nu)$\;
        确定$s>0$，$(\bm x_{i+1},\bm\lambda_{i+1},\bm\nu_{i+1})\leftarrow (\bm x_i,\bm\lambda_i,\bm\nu_i)+s(\Delta\bm x,\Delta\bm \lambda,\Delta\bm \nu)$\;
        $\eta\leftarrow-\bm f(\bm x_i)\bm \lambda_i$\;
        $t\leftarrow \mu m/\eta$\;
        \If{$\|\bm r_{dual}\|_2<\epsilon_{feas}$ {\bf{and}} $\|\bm r_{prim}\|_2<\epsilon_{feas}$ \bf{and} $\eta\le\epsilon$} {
            \Return $\bm x_{i+1}$
        }

    }
    \caption{原始对偶法}
    \label{prim_dual_method}
\end{algorithm}
其中$s$的确定是希望找到尽可能大的$s$，使得$\bm \lambda_{i+1}\succ \bm 0,\bm f(\bm x_{i+1})\prec\bm 0$，
同时$r_t$更小，同样用回溯直线搜索策略，不过并不使用Goldstein-Armijio规则。描述该策略如下：
\begin{enumerate}
    \item 计算最大的$s_{max}\le 1$使得$\bm\lambda+s_{max}\Delta\bm\lambda\succeq \bm 0$，令$s_0=0.99s_{max}$以保证$\bm\lambda+s_{0}\Delta\bm\lambda\succ \bm 0$。
    \item 迭代$s_k=\sigma s_{k-1},0<\sigma<1$，直到$f(\bm x+s_k\Delta\bm x)\prec 0$
    \item 继续迭代$s_k=\sigma s_{k-1}$，直到$\|r(\bm x+\Delta\bm x,\bm\lambda+\Delta\bm\lambda,\bm\nu+\Delta\bm\nu)\|_2\le(1-\alpha s)\|r_t(\bm x,\bm\lambda,\bm\nu)\|_2$
\end{enumerate}

\section{理论分析}
\subsection{时间复杂度分析}
在本节中，我们假定了$f(\bm x)\in\mathcal{S}_{\mu,L}^{2,2}(\mathbb{R}^n)$来分析复杂度，但是
更好的方式是使用\textbf{自和谐函数分析}，因为实际问题中$\mu,L$往往不可知，无法计算确切的迭代次数上界。这两种分析都涵盖了\textbf{线性规划}和\textbf{二次规划}。

另外本文并不会分析
一类问题的复杂度下界或者一类方法的复杂度上界。
\subsubsection{牛顿法分析}
先考虑内层牛顿迭代次数。上课已经讲到了牛顿法的局部收敛分析，即\ref{pre_know}提到的二阶收敛阶段。直接引用其结论：
\begin{thm}
    \label{newton_converge}
    若$f(\bm x)\in\mathcal{S}_{\mu,L}^{2,2}(\mathbb{R}^n)$，那么从满足$\|\bm x_0-\bm x^*\|<\bar r=\frac{2\mu}{3L}$的$\bm x_0$开始，牛顿法迭代产生的{$\bm x_k$}序列满足$\|\bm x_k-\bm x^*\|<\bar r,\|\bm x_{k+1}-\bm x^*\|\le \frac{L\|\bm x_k-\bm x^*\|^2}{2(\mu-L\|\bm x_k-\bm x^*\|)}$对所有非负整数$k$成立。
\end{thm}
根据定理\ref{newton_converge}，牛顿法在最优解附近二次收敛，将这部分迭代次数记为$\mathcal O(\log_2\log_2(1/\epsilon))$，其中$\epsilon$是误差阈值。

然而我们的方法中没有假定$\bm x_0$和$\bm x^*$足够近，因此还有阻尼阶段的收敛分析。有如下定理：
\begin{thm}
    \label{newton_converge_2}
    $f(\bm x)\in\mathcal{S}_{\mu,L}^{2,2}(\mathbb{R}^n)$，在$\|\bm x-\bm x^*\|\ge \bar r=\frac{2\mu}{3L}$的$\bm x$区域内迭代，即牛顿法尚未进入快速收敛阶段时，
    存在常数$\gamma>0$使得$f(\bm x_{k+1})-f(\bm x_k)\le -\gamma$，即每次迭代至少使函数值减少$\gamma$。
\end{thm}
\begin{proof}
$\mathcal S_{\mu,L}^{2,2}$隐含了一阶Lipschitz连续，二阶导有界，即存在常数$M>0$使得$\nabla^2f(\bm x)\preceq MI_n$。
由凸函数性质，
\begin{align*}
    f(\bm x+h\Delta\bm x)& \le f(\bm x)+h\nabla f(\bm x)^T\Delta\bm x+\frac{M\|\Delta\bm x\|^2}{2}h^2 \\
    & \le f(\bm x)+h\nabla f(\bm x)^T\Delta\bm x-\frac{M}{2\mu}h^2\Delta\bm x^T\nabla^2f(\bm x)\Delta\bm x\\
    & = f(\bm x)+(h-\frac{M}{2\mu}h^2)\nabla f(\bm x)^T\Delta\bm x
\end{align*}
其中第二步推导利用了$\nabla^2f(\bm x)\succeq \mu I_n$，
第三步推导是因为牛顿法选取的$\Delta \bm x$满足$\bm 0=\nabla f(\bm x)+\nabla^2f(\bm x)\Delta \bm x$
。取$\widehat h=\mu/M$，有
\begin{equation}
\label{armijio}
\begin{aligned}
    f(\bm x+\widehat h\Delta \bm x)&\le f(\bm x)+\frac{\mu}{2M}\nabla f(\bm x)^T\Delta\bm x\\
    &< f(\bm x)+\frac{\alpha \mu}{M}\nabla f(\bm x)^T\Delta\bm x\\
    &=f(\bm x)+\alpha \widehat h\nabla f(\bm x)^T\Delta\bm x
\end{aligned}
\end{equation}
其中$\alpha$是Goldstein-Armijio规则中的参数，\ref{pre_know}中提到取$\alpha<1/2$，所以第二步缩放成立。式\eqref{armijio}恰好就是Goldstein-Armijio的约束。\ref{pre_know}中已经介绍过，
我们在回溯直线搜索中每次让$h$乘以$\sigma$，所以最终找到的$h$至少满足$h\ge \sigma\widehat h=\sigma\mu/M$。对于这样的$h$，根据Goldstein-Armijio规则，
\begin{align*}
    f(\bm x+h\Delta\bm x)-f(\bm x)&\le \alpha h\nabla f(\bm x)^T\Delta\bm x \\
    & \le -\alpha\sigma\frac{\mu}{M}\nabla f(\bm x)^T\nabla^2f(\bm x)^{-1}\nabla f(\bm x) \\
    & \le -\alpha\sigma\frac{\mu}{M^2}\|\nabla f(\bm x)\|^2 \\
    & \le -\alpha\sigma\eta^2\frac{\mu}{M^2}
\end{align*}
其中常数$\eta$是$\|\nabla f(\bm x)\|$的下界，由于$\|\bm x-\bm x^*\|\ge \frac{2\mu}{3L}$，所以$\eta > 0$，所以存在常数$\gamma=\alpha\sigma\eta^2\frac{\mu}{M^2}>0$，使得
$\bm x$距离$\bm x^*$较远时，每次迭代函数值至少减少$\gamma $。

\end{proof}
由定理\ref{newton_converge}和定理\ref{newton_converge_2}可以估计牛顿法迭代次数为$\mathcal O((f(\bm x_0)-p^*)/\gamma+\log_2\log_2(1/\epsilon))$。
\label{time_complexity_newton}

\subsubsection{障碍方法分析}
考虑一轮牛顿迭代，有如下定理：
\begin{thm}
    \label{newton_barrier_ana}
    令$t_k=\mu^kt_0,k=1,2,...$，用牛顿法解$t=t_{k+1}(k\ge 0)$时的问题\ref{barrier_approx_prob_simple}，初始点为$\bm x_k=\bm x^*(t_{k})$，解出$\bm x_{k+1}=\bm x^*(t_k+1)$，那么牛顿迭代的次数为
    $\mathcal O(m(\mu-1-\log\mu)/\gamma+\log_2\log_2(1/\epsilon))$
\end{thm}
注意\ref{time_complexity_newton}小节中的$\mu$是凸参数，但定理\ref{newton_barrier_ana}的$\mu$是算法\ref{barrier_method}中的参数。对定理\ref{newton_barrier_ana}进行证明：
\begin{proof}
    综合定理\ref{newton_converge}和定理\ref{newton_converge_2}，写出定理\ref{newton_barrier_ana}牛顿法的迭代次数：
    $$\frac{\mu tf_0(\bm x_{k})+\phi(\bm x_k)-\mu tf_0(\bm x_{k+1})-\phi(\bm x_{k+1})}{\gamma}+\log_2\log_2(1/\epsilon)$$
    其中为了简化符号让问题\ref{barrier_approx_prob_simple}的目标函数乘了$t$。对第一项的分子进行缩放：
\begin{align*}
\mu tf_0&(\bm x_{k})+\phi(\bm x_k)-\mu tf_0(\bm x_{k+1})-\phi(\bm x_{k+1}) \\
&=\mu tf_0(\bm x_{k})-\mu tf_0(\bm x_{k+1})+\sum\limits_{i=1}^m{\log(-\mu t\lambda_if(\bm x_{k+1}))-m\log \mu} \\
&\le \mu tf_0(\bm x_k)-\mu tf_0(\bm x_{k+1})-\mu t\sum\limits_{i=1}^m{\lambda_i f_i(\bm x_{k+1})}-m-m\log \mu \\
&=\mu tf_0(\bm x_k)-\mu t\Big(f_0(\bm x_{k+1})+\sum\limits_{i=1}^m{\lambda_if_i(\bm x_{k+1})}+\bm \nu^T(A\bm x_{k+1}-\bm b)\Big)-m-m\log\mu\\
&\le \mu tf_0(\bm x_k)-\mu tg(\bm \lambda^*(t_k),\bm \nu^*(t_k))-m-m\log\mu\\
&=m(\mu-1-\log\mu)
\end{align*}
其中第一步变形
利用了$\lambda_if_i(\bm x)=1/t$，第二步放缩是不等式$x-1\ge \log x$，第三步变形是凑拉格朗日函数的形式，
第四步根据是$g(\lambda,\nu)$的定义，第五步用了式\eqref{dual_margin}。
\end{proof}
该证明来自于~\cite{10.5555/993483}一书第十章，其中的放缩相当具有技巧性，主干思路是凑$\bm x_{k+1}$处的拉格朗日函数，然后放缩到$\bm x_k$处的极值，从而消去$\bm x_{k+1}$。

到此为止，我们有了一轮牛顿法的迭代次数。根据式\eqref{dual_margin}，初始误差最大为$m/t_0$，每轮迭代$t_{k+1}=\mu t_k$，因而迭代轮数为
$\mathcal O(\log_\mu(\frac{m}{t_0\epsilon}))$。结合定理\ref{newton_barrier_ana}，并将$\log_2\log_2(1/\epsilon)$视作常数$c$，总的牛顿迭代次数上界为
$$\log_\mu(\frac{m}{t_0\epsilon})\Big(m(\mu-1-\log\mu)/\gamma+c\Big)$$

取$\mu=1+\frac{1}{\sqrt{m}}$，那么迭代次数为
$$\mathcal O(\log_\mu(\frac{m}{t_0\epsilon})\Big(m(\mu-1-\log\mu)/\gamma+c\Big))=O(\sqrt m\log \frac{m}{t_0\epsilon})$$
牛顿迭代最慢的数值计算是求Hessian的逆，因而算法\ref{barrier_method}总复杂度
为$$\mathcal O((n^3+K)\sqrt m\log \frac{m}{t_0\epsilon})$$
其中$K$是Hessian和梯度的Oracle操作代价。如果我们的最终目标不是控制误差在$\epsilon$之内，
而是将误差压缩固定倍数，即$\frac{m}{t_0\epsilon}$是常数，那么迭代次数是$\mathcal O(\sqrt m)$，这也是这类方法能做到的最好上界。
\label{time_complexity_barrier}
\subsubsection{原始对偶方法}
\label{time_complexity_pd}
算法\ref{prim_dual_method}的复杂度不好分析，退而求其次，我们简要描述\textbf{二次规划}问题使用算法\ref{prim_dual_method}求解复杂度的过程。
最终结果同样是$\mathcal O(\sqrt{m}\log\frac{1}{\epsilon})$的。我们考虑的二次规划问题描述如下：
\begin{problem}
    \label{quad_problem}
    最小化$\bm c^T\bm x+\frac{1}{2}\bm x^TQ\bm x$，使得$A\bm x=\bm b,\bm x\preceq \bm 0$
\end{problem}
其中$\bm c\in \mathbb{R}^n,Q\in \mathbb{R}^{n\times n},A\in\mathbb{R}^{p\times n},\bm b\in \mathbb{R}^p$且$Q\succeq 0$。

问题\ref{quad_problem}经过变形可以去掉等式约束，但是我们为了
和一般凸问题\ref{general_convex_prob}对齐，可以沿用各类符号，保留了等式约束。
注意不等式约束个数$m=n$，所以接下来$n$不再出现，全部用$m$代替。

二次规划下，式\eqref{kkt_vector_form}和\eqref{prim_dual_direction}分别变成式\eqref{eq_rt_quad}和\eqref{eq_direction_quad}。
式\eqref{eq_direction_quad}中，右侧一三两项直接设置为零，这是因为二次规划中这两项是一阶的，不需要近似，
因此只要初始时这两项为零，每次求出来的方向必然使这两项保持为零。
\newcommand{\bx}{\bm x}
\newcommand{\bl}{\bm \lambda}
\newcommand{\bn}{\bm \nu}
\newcommand{\bQ}{Q}
\newcommand{\bA}{A}
\newcommand{\AT}{A^T}
\newcommand{\bc}{\bm c}
\newcommand{\bb}{\bm b}
\newcommand{\diaglambda}{\textbf{diag}(\bm\lambda)}
\newcommand{\diagx}{\textbf{diag}(\bm x)}
\newcommand{\be}{\bm 1}
\newcommand{\dx}{\Delta\bm x}
\newcommand{\dl}{\Delta\bm \lambda}
\newcommand{\dn}{\Delta\bm \nu}
\begin{equation}
    \label{eq_rt_quad}
    r_t(\bx,\bl,\bn)=\begin{pmatrix}
        \bc+\bQ+\bl+\AT\bn\\
        -\diaglambda\bx-\frac{1}{t}\be\\
        \bA\bx-\bb
    \end{pmatrix}
\end{equation}
\begin{equation}
    \label{eq_direction_quad}
    \begin{pmatrix}
        \bQ &\bm I_n & \AT\\
        -\diaglambda& -\diagx & \bm 0 \\
        \bA & 0 & 0
    \end{pmatrix}
    \begin{pmatrix}
        \dx\\
        \dl\\
        \dn\\
    \end{pmatrix}=
    -\begin{pmatrix}
        \bc+\bQ+\bl+\AT\bn\\
        -\diaglambda\bx-\frac{1}{t}\be\\
        \bA\bx-\bb
    \end{pmatrix}=
    \begin{pmatrix}
        \bm 0\\
        \diaglambda\bx+\frac{1}{t}\be\\
        \bm 0\\
    \end{pmatrix}
\end{equation}

即便是二次规划，证明也比较复杂，这里给出证明两个关键定理，并用第二个定理求复杂度。定理的具体证明可以参考~\cite{wright1997primal}一书。
\begin{thm}
    \label{dist}
    对问题\ref{quad_problem}考虑算法\ref{prim_dual_method}。选取合适的$\mu$可以做到，如果初始参数$\bx _0,\bl _0,\bn _0,t_0$满足下列条件，那么取每次迭代步长必然可以取$s=1$，并且所有$\bx _k,\bl _k,\bn _k,t_k(k>0)$都满足下列条件：
    \begin{enumerate}
        \item $\bx$可行，$\bl,\bn$对偶可行。
        \item $\|\diaglambda\bx+\frac{1}{t}\bm 1\|\le \frac{\theta}{t}$
    \end{enumerate}
    其中$0<\theta<1$是较小的常数。
\end{thm}
\begin{thm}
    \label{bound}
    取$\mu=1-\beta/\sqrt m$，其中$\beta$是被$\theta$制约的较小常数，
    从定理\ref{dist}描述的可行点$\bx _0,\bl _0,\bn _0,t_0$出发，
    每次取步长$s=1$，那么$\frac{1}{t_{k+1}}\le (1-\frac{\beta}{2\sqrt m})\frac{1}{t_k}$对所有$k\ge 0$成立。
\end{thm}

有了定理\ref{bound}，复杂度就很容易求了。第$k$次迭代误差上限$\eta_k=\mu m/t_k$，所以$\eta_{k+1}\le (1-\frac{\beta}{2\sqrt m})\eta_k$。所以总迭代次数为
$\mathcal O(\frac{\log\frac{m}{t_0\epsilon}}{-\log(1-\frac{\beta}{2\sqrt m})})$，用$log(1-x)\le -x$放缩得迭代次数为$\mathcal O(\log\frac{m}{t_0\epsilon}/\frac{\beta}{2\sqrt m})=\mathcal O(\sqrt m\log\frac{m}{t_0\epsilon})$。
这个结论和障碍方法是一样的。

\subsection{对比}
直观来讲，原始对偶方法适应性地控制路径在中心点附近，会根据当前误差控制接近中心路径的程度。
而障碍方法严格地跟踪中心路径，所以障碍方法效率会低一点。不过从复杂度分析来看他们都做到了这类问题的下界，分不出高下。有的原始对偶方法复杂度差于障碍方法，但是实际效率跑得会更快。

尽管\ref{time_complexity_pd}中对原始对偶复杂度的证明需要初始点可行，\ref{text_prim_dual}介绍的原始对偶方法初始点允许是不可行的。障碍方法则必须先找到一个初始可行点。

\label{time_complexity}
\section{应用}
\subsection{优化问题}
原始对偶方法在线性规划领域的应用最出名，从实际效率和精度来看，它是线性规划问题相当具有竞争力的解决方法，
障碍方法则一般用于非线性问题。

原始对偶法起源于线性规划问题，后来被推广于很多非线性问题，比如半正定规划和二次规划。应用在
二次规划问题的原始对偶法已经在\ref{time_complexity_pd}提到过了。半正定规划问题描述如下：
\newcommand{\bF}{F}
\newcommand{\bG}{G}
\begin{problem}
    最小化$\bc^T\bx$使得$x_1\bF _1+\dots+x_n\bF _n+\bG\preceq \bm 0,\bA \bx = \bb$
\end{problem}
其中$\bG,\bF _1,...,\bF _n\in\mathbb{R}^{k\times k}$都是对称矩阵，$\bA\in\mathbb{R}^{p\times n}$。
\subsection{机器学习}
机器学习就是在做数据拟合，
先确定函数形式，然后通过数据去学习函数的参数。而数据拟合问题都会被转化成优化问题。
比如很经典的二分类器SVM，可以描述其原型问题如下：
\begin{problem}
    最小化$\frac{1}{n}\sum\limits_{i=1}^n\zeta_i+\lambda\|\bm w\|^2$使得$y_i(\bm x_i^T\bm w+b)\ge1-\zeta_i,\zeta_i\ge0$对$i=1,...,n$成立。
\end{problem}
该问题符合二次规划的形式，可以直接套用内点法求参数。

机器学习问题常见的损失函数如Mean Squared Error,Hinge Loss,Cross-Entropy Loss等等，很多时候它们组成的目标函数是凸的，甚至是光滑的，那么用内点法就成为可能。
2002年Ferris等人就在用内点法做大规模数据的SVM~\cite{ferris2002interior}，2011年也有~\cite{woodsend2011exploiting}。

\section{总结}
内点法是优化问题中非常重要的一类数值方法，它的速度快，精度也很高。它起源于非线性问题，
却在线性规划问题上发扬光大，最终又被推广到非线性优化问题。一类内点法会利用障碍函数消除不等式约束，
然后使问题变成解最优条件的形式，解最优条件可以用牛顿法；另一类内点法是考虑对偶问题，
和原问题一起迭代寻找最优解，它其实和前一类方法联系紧密，但是本质不同，效率也更好。对于本文提到的两个方法，
它们复杂度上界都是$\mathcal O(\sqrt m\log(\frac{1}{\epsilon}))$，不过实际迭代次数通常会少得多。
不过内点法也存在局限，本文中的分析假定了函数二阶导连续，适用性不如使用次梯度的方法广泛。


\bibliography{a}{}
\bibliographystyle{plain}
\end{document}
\end{document}

$TODO 所有矩阵符号加粗$